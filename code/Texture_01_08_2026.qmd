---
title: "Texture_05_23_2025"
format: html
author: "Madelyn Willis"
---

### 1. Packages

```{r Load Libraries}
library(dplyr)
library(ggplot2)
library(tidyr)
library(tidyverse)
library(purrr)
library(tibble)
library(readxl)
library(writexl)
library(janitor)
library(aqp)
library(Hmisc)
library(soiltexture)
library(kableExtra)
library(knitr)
library(readr)
library(stringr)
library(lubridate)
```

### 2. Load Data

```{r Pull Data, warning=FALSE}
#Step 1: pull data and calculate silt %
results_df <- list.files("../data/LPSA/LPSA data/", pattern = "\\.(csv|CSV)$", recursive = TRUE, full.names = TRUE) %>%
  map_dfr(function(file_path) {
    # Read the file
    df <- read_csv(file_path, col_names = FALSE, show_col_types = FALSE) %>%
      filter(!if_all(everything(), is.na))  # Remove completely empty rows

    # Locate `% <` and `% >` tables in column B
    percent_less_start <- which(df[[2]] == "% <" & df[[1]] == "Size")
    percent_greater_start <- which(df[[2]] == "% >" & df[[1]] == "Size")

    # Skip files without both tables
    if (length(percent_less_start) == 0 || length(percent_greater_start) == 0) {
      warning(paste("Required tables `% <` or `% >` not found in file:", file_path))
      return(NULL)
    }

    # Extract rows and validate structure for clay and sand
    percent_less_row <- percent_less_start[1]
    percent_greater_row <- percent_greater_start[1]

    clay_row <- percent_less_row + 1
    sand_row <- percent_greater_row + 2

    if (df[clay_row, 1] != "2") {
      warning(paste("Expected `2` under `% <` not found in file:", file_path))
      return(NULL)
    }
    if (df[sand_row, 1] != "50") {
      warning(paste("Expected `50` under `% >` not found in file:", file_path))
      return(NULL)
    }

    # Extract clay and sand values
    clay <- as.numeric(gsub("[^0-9\\.]+", "", df[clay_row, 2]))
    sand <- as.numeric(gsub("[^0-9\\.]+", "", df[sand_row, 2]))

    # Validate extracted values
    if (is.na(clay) || is.na(sand) || clay < 0 || sand < 0 || clay + sand > 100) {
      warning(paste("Invalid clay and sand values in file:", file_path))
      return(NULL)
    }

    # Extract meta information: ID, base_ID, and sample_date
    sample_id <- as.character(df[4, 2][[1]])
    if (is.na(sample_id) || sample_id == "") {
      warning(paste("Sample ID missing or invalid for file:", file_path))
      return(NULL)
    }
    base_id <- str_remove(sample_id, "[A-Z]$")  # Base ID (excluding final letter)
    sample_date <- basename(dirname(file_path))  # Extract folder name as date

    # Return results
    tibble(
      ID = sample_id,
      base_ID = base_id,
      sample_date = sample_date,
      clay = clay,
      sand = sand,
      silt = 100 - (clay + sand)  # Calculate silt
    )
  }) %>%
  mutate(
    CLAYPCT = clay / 100,  # Add percent columns for consistency
    SANDPCT = sand / 100,
    SILTPCT = silt / 100
  ) %>%
  select(ID, base_ID, sample_date, CLAYPCT, SANDPCT, SILTPCT, clay, sand, silt) %>%
  arrange(sample_date)

print("Final Results Dataframe:")
print(results_df)
```




### 3. Detect Failures

```{r detect failure, warning = FALSE}
# 3. Detect differences > 5 between replicates
check_differences <- function(df) {
  n <- nrow(df)
  if (n < 2) return(tibble())
  combn(n, 2, simplify = FALSE) %>%
    map_dfr(~{
      row1 <- df[.x[1], ]
      row2 <- df[.x[2], ]
      tibble(
        base_ID = row1$base_ID,
        ID_1 = row1$ID,
        ID_2 = row2$ID,
        diff_sand = abs(row1$sand - row2$sand),
        diff_clay = abs(row1$clay - row2$clay),
        diff_silt = abs(row1$silt - row2$silt)
      )
    }) %>%
    filter(diff_sand > 5 | diff_clay > 5 | diff_silt > 5)
}

failures_df <- results_df %>%
  group_by(base_ID) %>%
  group_map(~ check_differences(.x)) %>%
  bind_rows()

# failures_table <- failures_df %>%
#   kable(caption = "Replicate Pairs with >5% Difference in Texture Components", format = "html") %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
# failures_table


```

### 3.5. High dilution detection

```{r Detect high dilution samples, warning = FALSE}
folder <- "../data_do_not_push/LPSA data/"
dfiles <- list.files(folder, pattern = "\\.\\$(ls|av)$", recursive = TRUE, ignore.case = TRUE)

extract_sample_num <- function(filename) {
  # Adjust this regex as needed for your actual file name format!
  # This will find a sequence of digits followed by a capital letter
  match <- regexpr("[0-9]+[A-Z]", filename)
  if (match[1] != -1) {
    substr(filename, match[1], match[1] + attr(match, "match.length") - 1)
  } else {
    NA
  }
}

extract_dilution <- function(filepath) {
  lines <- readLines(filepath)
  # Find the line that contains "Dilutions="
  dil_line <- grep("Dilutions=", lines, value = TRUE)
  if (length(dil_line) > 0) {
    # Extract the number after "Dilutions="
    as.numeric(sub(".*Dilutions= *([0-9]+).*", "\\1", dil_line[1]))
  } else {
    NA
  }
}

dfiles <- list.files(folder, pattern = "\\.\\$(ls|av)$", recursive = TRUE, ignore.case = TRUE)

results <- lapply(dfiles, function(file) {
  sample_num <- extract_sample_num(file)
  dilution <- extract_dilution(file.path(folder, file))
  data.frame(sample_num = sample_num, dilution = dilution, filename = file, stringsAsFactors = FALSE)
})

dilutions <- do.call(rbind, results)
print(dilutions)

filtered_df15 <- subset(dilutions, dilution > 14) %>%
#unique samples with high dilution
  group_by(sample_num) %>%
  summarise(dilution = max(dilution), filename = first(filename), .groups = "drop")

#filter by 10-14 dilutions
filtered_df10_14 <- subset(dilutions, dilution > 10 & dilution <= 14) %>%
  group_by(sample_num) %>%
  summarise(dilution = max(dilution), filename = first(filename), .groups = "drop")
```


### 4. Texture for all samples

```{r All Samples, warning = FALSE}
# Step 3: Main texture class
selected_data <- results_df %>% 
  select(CLAY = clay, SILT = silt, SAND = sand) %>%
  as.data.frame()

texture_classes <- TT.points.in.classes(
  tri.data = selected_data,
  class.sys = "USDA.TT"
)
TT.plot(
  tri.data = selected_data,
  class.sys = "USDA.TT",
  col = "black",
  pch = 19,
  cex = 0.5,
  main = "Texture Classes for All Soil Samples"
)
# Extract primary and boundary info
texture_info <- apply(texture_classes, 1, function(x) {
  max_val <- max(x)
  classes <- colnames(texture_classes)[which(x == max_val)]
  list(
    primary = classes[1],  # first class if tie
    is_boundary = length(classes) > 1,
    boundary_classes = if(length(classes) > 1) paste(classes, collapse = " / ") else NA_character_
  )
})

# Add results back to results_df
results_df <- results_df %>%
  mutate(
    primary_texture = sapply(texture_info, `[[`, "primary"),
    is_boundary = sapply(texture_info, `[[`, "is_boundary"),
    boundary_classes = sapply(texture_info, `[[`, "boundary_classes")
  )

# Map USDA texture names to simplified classes
results_df <- results_df %>%
  mutate(
    texture_class = case_when(
      primary_texture == "SaClLo" ~ "SCL",
      primary_texture == "Clo" ~ "CL",
      primary_texture == "SaLo" ~ "SL",
      primary_texture == "SaCl" ~ "SC",
      primary_texture == "Lo" ~ "L",
      primary_texture == "LoSa" ~ "LS",
      primary_texture == "S" ~ "S",
      primary_texture == "Cl" ~ "C",
      primary_texture == "Si" ~ "SI",
      primary_texture == "SiL" ~ "SIL",
      primary_texture == "SiCl" ~ "SIC",
      primary_texture == "SiClLo" ~ "SICL",
      primary_texture == "SiLo" ~ "SIL",
      primary_texture == "Sa" ~ "S",
      TRUE ~ as.character(primary_texture)
    )
  )


results_df <- results_df %>%
  dplyr::select(ID = ID, CLAY = clay, SAND = sand, SILT = silt, texture_class, is_boundary, boundary_classes, base_ID, sample_date) 

results_table <- results_df %>%
  kable(caption = "Texture Classifications for All Soil Samples", format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  scroll_box(height = "400px")
results_table

# write.csv(results_df, "../output (DO NOT PUSH)//all_results_texture_05_23_2025.csv", row.names = FALSE)  # <-- include per-sample output too
#save results as csv:
today <- format(Sys.Date(), "%m_%d_%Y")
filename <- paste0("../output_do_not_push/all_results_texture_", today, ".csv")
write.csv(results_df, filename, row.names = FALSE)

```

### 5. Texture for grouped IDs

```{r Grouped IDs, warning = FALSE}
# Count number of replicates per base_ID
replicate_counts <- results_df %>%
  count(base_ID) %>%
  filter(n > 1)

# Filter results_df to only those base_IDs with >1 replicate
filtered_results_df <- results_df %>%
  filter(base_ID %in% replicate_counts$base_ID)

# Now summarize filtered data
summary_df <- filtered_results_df %>%
  group_by(base_ID) %>%
  summarise(
    SAND = mean(SAND, na.rm = TRUE),
    SILT = mean(SILT, na.rm = TRUE),
    CLAY = mean(CLAY, na.rm = TRUE),
    .groups = "drop"
  )

selected_data <- summary_df %>%
  select(CLAY,SILT,SAND) %>%
  as.data.frame()

summary_matrix <-  TT.points.in.classes(
  tri.data = selected_data %>%
    select(CLAY, SILT, SAND),
  class.sys = "USDA.TT")

summary_raw_names <- apply(summary_matrix, 1, function(x) colnames(summary_matrix)[which(x == 1)][1])

summary_df$texture_class <- case_when(
  summary_raw_names == "SaClLo" ~ "SCL",
  summary_raw_names == "Clo" ~ "CL",
  summary_raw_names == "SaLo" ~ "SL",
  summary_raw_names == "SaCl" ~ "SC",
  summary_raw_names == "Lo" ~ "L",
  summary_raw_names == "LoSa" ~ "LS",
  summary_raw_names == "S" ~ "S",
  summary_raw_names == "Cl" ~ "C",
  summary_raw_names == "Si" ~ "SI",
  summary_raw_names == "SiL" ~ "SIL",
  summary_raw_names == "SiCl" ~ "SIC",
  summary_raw_names == "SiClLo" ~ "SICL",
  summary_raw_names == "SiLo" ~ "SIL",
  summary_raw_names == "Sa" ~ "S",
  TRUE ~ summary_raw_names
)

summary_df <- summary_df %>%
  dplyr::select(ID = base_ID, CLAY, SAND, SILT, texture_class) %>%
  mutate(CLAYPCT = CLAY / 100,
         SANDPCT = SAND / 100) %>%
  clean_names()

# Join sample_date back in, based on filtered results
summary_df <- summary_df %>%
  left_join(filtered_results_df %>% select(base_ID, sample_date) %>% distinct(), by = c("id" = "base_ID")) %>%
# Remove duplicates
  distinct(id, .keep_all = TRUE) %>%
  arrange(sample_date)
summary_table <- summary_df %>%
  kable(caption = "Averaged Texture Classes by ID (replicates are grouped)", format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
summary_table
#write as csv:
today <- format(Sys.Date(), "%m_%d_%Y")
filename <- paste0("../output_do_not_push/summarized_texture_", today, ".csv")
write.csv(summary_df, filename, row.names = FALSE)
```


### 6. Texture Differences in Failures

```{r Complete Fails}
# Add texture class for ID_1 and ID_2 
failures_df <- failures_df %>%
  left_join(results_df %>% select(ID, texture_class), by = c("ID_1" = "ID")) %>%
  rename(texture_class_1 = texture_class) %>%
  left_join(results_df %>% select(ID, texture_class), by = c("ID_2" = "ID")) %>%
  rename(texture_class_2 = texture_class)

# Filter for differences in texture class
failures_diff_texture <- failures_df %>%
  filter(texture_class_1 != texture_class_2)
#filter for where the texture classes are not different:
failures_same_texture <- failures_df %>%
  filter(texture_class_1 == texture_class_2)
# Create table of failures with texture differences
failures_diff_texture_table <- failures_diff_texture %>%
  kable(caption = "Failed Textures: Must redo textures:", format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
failures_diff_texture_table


failures_same_texture_table <- failures_same_texture %>%
  kable(caption = "Failed Textures with same texture class", format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
failures_same_texture_table

#find samples where base Id is found in failures_diff_texture but not failures_same_texture

```

### 7. Final averaged textures for HZ

```{r}
# Step 1: Filter out samples with CLAY >= 80% ---------------------------------
filtered_results <- results_df %>%
  filter(CLAY < 80)  # Remove high-clay samples

# Debug: Check how many rows remain after filtering
cat("Total rows after filtering high-clay samples:", nrow(filtered_results), "\n")

# Step 2: Group by base_ID and calculate averages -----------------------------
averaged_results <- filtered_results %>%
  group_by(base_ID) %>%
  summarise(
    avg_clay = mean(CLAY, na.rm = TRUE),  # Average CLAY
    avg_silt = mean(SILT, na.rm = TRUE),  # Average SILT
    avg_sand = mean(SAND, na.rm = TRUE),  # Average SAND
    num_replicates = n(),                # Count replicates
    .groups = "drop"                     # Drop grouping for clean final results
  )

# Step 3: Assign texture classes for averaged results -------------------------
# Prepare data for USDA texture classification
selected_data <- averaged_results %>%
  select(CLAY = avg_clay, SILT = avg_silt, SAND = avg_sand) %>%
  as.data.frame()

# Classify soil samples into USDA texture classes
texture_classes <- TT.points.in.classes(
  tri.data = selected_data,
  class.sys = "USDA.TT"
)

# Determine primary texture, boundary status, and multiple classes (boundary cases)
texture_info <- apply(texture_classes, 1, function(x) {
  max_val <- max(x)
  classes <- colnames(texture_classes)[which(x == max_val)]
  list(
    primary = classes[1],  # Use the first class in case of ties
    is_boundary = length(classes) > 1,
    boundary_classes = if (length(classes) > 1) paste(classes, collapse = " / ") else NA_character_
  )
})

# Add texture classification details back to the averaged results
averaged_results <- averaged_results %>%
  mutate(
    primary_texture = sapply(texture_info, `[[`, "primary"),
    is_boundary = sapply(texture_info, `[[`, "is_boundary"),
    boundary_classes = sapply(texture_info, `[[`, "boundary_classes")
  )

# Simplify texture classes
averaged_results <- averaged_results %>%
  mutate(
    texture_class = case_when(
      primary_texture == "SaClLo" ~ "SCL",
      primary_texture == "Clo" ~ "CL",
      primary_texture == "SaLo" ~ "SL",
      primary_texture == "SaCl" ~ "SC",
      primary_texture == "Lo" ~ "L",
      primary_texture == "LoSa" ~ "LS",
      primary_texture == "S" ~ "S",
      primary_texture == "Cl" ~ "C",
      primary_texture == "Si" ~ "SI",
      primary_texture == "SiL" ~ "SIL",
      primary_texture == "SiCl" ~ "SIC",
      primary_texture == "SiClLo" ~ "SICL",
      primary_texture == "SiLo" ~ "SIL",
      primary_texture == "Sa" ~ "S",
      TRUE ~ primary_texture  # Use the USDA class if not mapped
    )
  )

# Step 4: Generate and save results tables -------------------------------------
# Final table: Flatten results for export
final_results <- averaged_results %>%
  clean_names()  # Ensure consistent column naming

# Save the summarized texture classification results
today <- format(Sys.Date(), "%m_%d_%Y")
summary_filename <- paste0("../output_do_not_push/grouped_texture_", today, ".csv")
write.csv(final_results, summary_filename, row.names = FALSE)

cat("Final summarized results saved to file:", summary_filename, "\n")

# Generate an HTML results table for markdown or reports
results_table <- final_results %>%
  select(base_id, avg_clay, avg_silt, avg_sand, texture_class, num_replicates, is_boundary, boundary_classes) %>%
  kable(
    caption = "Summarized Texture Classifications by Base ID",
    format = "html"
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  scroll_box(height = "400px")

cat("\nSummary Table:\n")
print(results_table)

# Save the filtered per-sample results if needed
per_sample_filename <- paste0("../output_do_not_push/all_filtered_samples_", today, ".csv")
write.csv(filtered_results, per_sample_filename, row.names = FALSE)

cat("Filtered per-sample results saved to file:", per_sample_filename, "\n")

```

```{r}
#final texture for base Ids, only averaging samples with same base ID that had the same texture class. It is OK if they failed. Also removing samples that had clay at 80% or more. 
# STEP 1: Filter out samples with CLAY >= 80%
filtered_results <- results_df %>%
  filter(CLAY < 80)  # Retain only rows with CLAY < 80%

# STEP 2: Group by base_ID and texture_class, then compute averages
final_texture <- filtered_results %>%
  group_by(base_ID, texture_class) %>%
  summarise(
    avg_clay = mean(CLAY, na.rm = TRUE),  # Average CLAY
    avg_silt = mean(SILT, na.rm = TRUE),  # Average SILT
    avg_sand = mean(SAND, na.rm = TRUE),  # Average SAND
    num_replicates = n(),                # Number of replicates in the group
    .groups = "drop"                     # Drop grouping for a clean final output
  )

# STEP 3: Save the final results as a CSV file
today <- format(Sys.Date(), "%m_%d_%Y")
output_filename <- paste0("../output_do_not_push/final_texture_averages_", today, ".csv")
write.csv(final_texture, output_filename, row.names = FALSE)

# Print the final table for review
cat("\nFinal Averaged Texture Results:\n")
print(final_texture)

```

### 7. Particle Size Classifications

```{r Particle Class}


df_raw <- read.csv("../data_do_not_push/LPSA data/June 2nd, 2025/Perry_250333A_ 2 Jun 2025_08-24_30.$av..csv", header = FALSE, stringsAsFactors = FALSE)

particle_table <- df_raw[67:nrow(df_raw), c("V1", "V2")]
colnames(particle_table) <- c("diameter_um", "volume_pct")

# Convert to numeric
particle_table$diameter_um <- as.numeric(particle_table$diameter_um)
particle_table$volume_pct <- as.numeric(particle_table$volume_pct)

# Drop any rows that are NA (in case the file has blank lines at the end)
particle_table <- particle_table[!is.na(particle_table$diameter_um) & !is.na(particle_table$volume_pct), ]

# View result
head(particle_table)
summary(particle_table)

# Replace these with your actual limits and class names
custom_classes <- data.frame(
  class = c(
    "fine_clay", "coarse_clay", "fine_silt", "coarse_silt",
    "very_fine_sand", "fine_sand", "medium_sand", "coarse_sand", "very_coarse_sand",
    "fine_gravel", "medium_gravel", "coarse_gravel", "cobbles", "stones", "boulders"
  ),
  upper_um = c(
    0.2, 2, 20, 50, 100, 250, 500, 1000, 2000,
    5000, 20000, 76000, 250000, 600000, Inf
  )
)

assign_custom_class <- function(d) {
  idx <- which(d <= custom_classes$upper_um)[1]
  custom_classes$class[idx]
}

particle_table$custom_class <- sapply(particle_table$diameter_um, assign_custom_class)

class_summary <- aggregate(volume_pct ~ custom_class, data = particle_table, sum)
print(class_summary)

# Assign your fine classes to USDA groups
clay_classes <- c("fine_clay", "coarse_clay")
silt_classes <- c("fine_silt", "coarse_silt")
sand_classes <- c("very_fine_sand", "fine_sand", "medium_sand", "coarse_sand", "very_coarse_sand")

# For subclass rules, keep the sand splits
sand_subclasses <- c("very_coarse_sand", "coarse_sand", "medium_sand", "fine_sand", "very_fine_sand")

# Calculate broad fractions
pct_clay <- sum(class_summary$volume_pct[class_summary$custom_class %in% clay_classes])
pct_silt <- sum(class_summary$volume_pct[class_summary$custom_class %in% silt_classes])
pct_sand <- sum(class_summary$volume_pct[class_summary$custom_class %in% sand_classes])

# For sand splits
pct_vcs <- class_summary$volume_pct[class_summary$custom_class == "very_coarse_sand"]
pct_cs  <- class_summary$volume_pct[class_summary$custom_class == "coarse_sand"]
pct_ms  <- class_summary$volume_pct[class_summary$custom_class == "medium_sand"]
pct_fs  <- class_summary$volume_pct[class_summary$custom_class == "fine_sand"]
pct_vfs <- class_summary$volume_pct[class_summary$custom_class == "very_fine_sand"]

# If any are missing, make sure they're 0
if(length(pct_vcs)==0) pct_vcs <- 0
if(length(pct_cs)==0) pct_cs <- 0
if(length(pct_ms)==0) pct_ms <- 0
if(length(pct_fs)==0) pct_fs <- 0
if(length(pct_vfs)==0) pct_vfs <- 0

assign_usda_texture_subclass <- function(pct_clay, pct_silt, pct_sand, 
                                         pct_vcs, pct_cs, pct_ms, pct_fs, pct_vfs) {
  # SAND GROUPS (Sands, coarse sand, sand, fine sand, very fine sand)
  if (pct_sand > 85 && (pct_silt + 1.5 * pct_clay) < 15) {
    if ((pct_vcs + pct_cs) >= 25 && max(pct_ms, pct_fs, pct_vfs) < 50) {
      return("coarse sand")
    } else if ((pct_fs >= 50 && pct_fs > pct_vfs) ||
               ((pct_vcs + pct_cs + pct_ms) < 25 && pct_vfs < 50)) {
      return("fine sand")
    } else if (pct_vfs >= 50) {
      return("very fine sand")
    } else {
      return("sand")
    }
  }
  # LOAMY SANDS (apply similar logic for loamy subclasses)
  if (pct_sand >= 70 && pct_sand <= 90 && (pct_silt + 1.5 * pct_clay) >= 15 && (pct_silt + 2*pct_clay) < 30) {
    if ((pct_vcs + pct_cs) >= 25 && max(pct_ms, pct_fs, pct_vfs) < 50) {
      return("loamy coarse sand")
    } else if ((pct_fs >= 50 && pct_fs > pct_vfs) ||
               ((pct_vcs + pct_cs + pct_ms) < 25 && pct_vfs < 50)) {
      return("loamy fine sand")
    } else if (pct_vfs >= 50) {
      return("loamy very fine sand")
    } else {
      return("loamy sand")
    }
  }
  # SANDY LOAMS
  if (((pct_clay >= 7 && pct_clay < 20 && pct_sand > 52 && (pct_silt + 2*pct_clay) >= 30)) ||
      (pct_clay < 7 && pct_silt < 50 && (pct_silt + 2*pct_clay) >= 30)) {
    return("sandy loam")
  }
  # LOAM
  if (pct_clay >= 7 && pct_clay < 27 && pct_silt >= 28 && pct_silt < 50 && pct_sand <= 52) {
    return("loam")
  }
  # SILT LOAM
  if ((pct_silt >= 50 && pct_clay >= 12 && pct_clay < 27) ||
      (pct_silt >= 50 && pct_silt < 80 && pct_clay < 12)) {
    return("silt loam")
  }
  # SILT
  if (pct_silt >= 80 && pct_clay < 12) {
    return("silt")
  }
  # SANDY CLAY LOAM
  if (pct_clay >= 20 && pct_clay < 35 && pct_silt < 28 && pct_sand > 45) {
    return("sandy clay loam")
  }
  # CLAY LOAM
  if (pct_clay >= 27 && pct_clay < 40 && pct_sand > 20 && pct_sand <= 45) {
    return("clay loam")
  }
  # SILTY CLAY LOAM
  if (pct_clay >= 27 && pct_clay < 40 && pct_sand <= 20) {
    return("silty clay loam")
  }
  # SANDY CLAY
  if (pct_clay >= 35 && pct_sand > 45) {
    return("sandy clay")
  }
  # SILTY CLAY
  if (pct_clay >= 40 && pct_silt >= 40) {
    return("silty clay")
  }
  # CLAY
  if (pct_clay >= 40 && pct_sand <= 45 && pct_silt < 40) {
    return("clay")
  }
  # If none fit, return "unclassified"
  return("unclassified")
}

# Call with your numbers:
usda_texture <- assign_usda_texture_subclass(
  pct_clay, pct_silt, pct_sand, pct_vcs, pct_cs, pct_ms, pct_fs, pct_vfs
)

cat("USDA texture class/subclass:", usda_texture, "\n")
```

```{r}
# library(soiltexture)
# library(dplyr)
# 
# # Assuming `selected_data` has columns: clay, silt, sand, base_ID
# 
# # Step 1: Define color palette and assign to base_ID
# unique_ids <- unique(selected_data$base_ID)
# colors <- rainbow(length(unique_ids))
# names(colors) <- unique_ids
# 
# # Step 2: Assign colors to each row based on base_ID
# selected_data$color <- colors[selected_data$base_ID]
# 
# # Step 3: Plot with color
# TT.plot(
#   tri.data = selected_data,
#   class.sys = "USDA.TT",
#   col = selected_data$color,
#   pch = 19,
#   cex = 0.5,
#   main = "Texture Classes Colored by Base ID"
# )
# # Step 4: Add legend
# legend("topright", legend = unique_ids, col = colors, pch = 19, cex = 0.6)

```

